{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59d9e97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sahil\\AppData\\Local\\Temp\\ipykernel_6640\\3225021342.py:7: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.layers import LeakyReLU, ReLU, ELU, PReLU\n",
    "from tensorflow.keras.optimizers import Adam,SGD,RMSprop,Adagrad\n",
    "from kerastuner.tuners import RandomSearch\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c5dcdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               patience=20,\n",
    "                               mode='auto',\n",
    "                               restore_best_weights=False,\n",
    "                               baseline=None,\n",
    "                              #  min_delta = 0.0001,\n",
    "\n",
    "                              )\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_model.h5',       # File name to save the model\n",
    "    monitor='val_loss',             # Metric to monitor (commonly val_loss or val_accuracy)\n",
    "    save_best_only=True,            # Save only when performance improves\n",
    "    mode='min',                     # 'min' if you're monitoring loss; 'max' for accuracy\n",
    "    save_weights_only=False,        # Set to True if you only want to save weights\n",
    "    verbose=1                       # Print a message each time model is saved\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a558bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    for i in range(hp.Int('num_of_layers',2,10)):\n",
    "        if i == 0:\n",
    "            model.add(Dense(\n",
    "                units = hp.Int('units'+str(i),min_value = 2 , max_value = 528,step = 8),\n",
    "                activation = hp.Choice('activation' + str(i),values = ['relu','tanh','sigmoid','elu','selu']),\n",
    "                input_dim = 11\n",
    "            ))\n",
    "        else:\n",
    "            model.add(Dense(\n",
    "                units = hp.Int('units'+str(i),min_value = 2 , max_value = 528,step = 8),\n",
    "                activation = hp.Choice('activation' + str(i),values = ['relu','tanh','sigmoid','elu','selu']),\n",
    "            ))\n",
    "\n",
    "    model.add(Dense(units=1,activation='sigmoid'))\n",
    "    \n",
    "    # Choose optimizer\n",
    "    optimizer_name = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])\n",
    "\n",
    "    # Set optimizer-specific parameters\n",
    "    if optimizer_name == 'adam':\n",
    "        learning_rate = hp.Float('adam_lr', 1e-5, 1e-2, sampling='log')\n",
    "        beta_1 = hp.Float('adam_beta_1', 0.8, 0.99, step=0.01)\n",
    "        beta_2 = hp.Float('adam_beta_2', 0.9, 0.999, step=0.01)\n",
    "        optimizer = Adam(\n",
    "            learning_rate=learning_rate,\n",
    "            beta_1=beta_1,\n",
    "            beta_2=beta_2\n",
    "        )\n",
    "\n",
    "    elif optimizer_name == 'sgd':\n",
    "        learning_rate = hp.Float('sgd_lr', 1e-5, 1e-1, sampling='log')\n",
    "        momentum = hp.Float('sgd_momentum', 0.0, 0.9, step=0.1)\n",
    "        nesterov = hp.Boolean('sgd_nesterov')\n",
    "        optimizer = SGD(\n",
    "            learning_rate=learning_rate,\n",
    "            momentum=momentum,\n",
    "            nesterov=nesterov\n",
    "        )\n",
    "\n",
    "    elif optimizer_name == 'rmsprop':\n",
    "        learning_rate = hp.Float('rmsprop_lr', 1e-5, 1e-2, sampling='log')\n",
    "        rho = hp.Float('rmsprop_rho', 0.8, 0.99, step=0.01)\n",
    "        momentum = hp.Float('rmsprop_momentum', 0.0, 0.9, step=0.1)\n",
    "        optimizer = RMSprop(\n",
    "            learning_rate=learning_rate,\n",
    "            rho=rho,\n",
    "            momentum=momentum\n",
    "        )\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8226f335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Ann PROJECT\\mysvenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=15,\n",
    "    directory = 'project',\n",
    "    project_name = 'churn'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0f0b0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Churn_Modelling.csv')\n",
    "\n",
    "with open('model.m5','rb') as f:\n",
    "    model = dill.load(f)\n",
    "\n",
    "\n",
    "transformed_data = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c37017ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(transformed_data,df.iloc[:,-1],test_size=0.3,random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c229b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 Complete [00h 00m 07s]\n",
      "val_accuracy: 0.8293333053588867\n",
      "\n",
      "Best val_accuracy So Far: 0.8650000095367432\n",
      "Total elapsed time: 00h 02m 31s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train,y_train,epochs=10,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2b0a613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Ann PROJECT\\mysvenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "d:\\Ann PROJECT\\mysvenv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "bestmodel = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bea2d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "\u001b[1m208/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8517 - loss: 0.3595\n",
      "Epoch 12: val_loss improved from inf to 0.35985, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8514 - loss: 0.3598 - val_accuracy: 0.8583 - val_loss: 0.3599\n",
      "Epoch 13/100\n",
      "\u001b[1m203/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8561 - loss: 0.3510\n",
      "Epoch 13: val_loss improved from 0.35985 to 0.34095, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8557 - loss: 0.3515 - val_accuracy: 0.8643 - val_loss: 0.3409\n",
      "Epoch 14/100\n",
      "\u001b[1m186/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8574 - loss: 0.3516\n",
      "Epoch 14: val_loss did not improve from 0.34095\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8572 - loss: 0.3515 - val_accuracy: 0.8603 - val_loss: 0.3507\n",
      "Epoch 15/100\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8556 - loss: 0.3441\n",
      "Epoch 15: val_loss improved from 0.34095 to 0.33477, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8556 - loss: 0.3442 - val_accuracy: 0.8670 - val_loss: 0.3348\n",
      "Epoch 16/100\n",
      "\u001b[1m184/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8605 - loss: 0.3464\n",
      "Epoch 16: val_loss did not improve from 0.33477\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8596 - loss: 0.3473 - val_accuracy: 0.8617 - val_loss: 0.3520\n",
      "Epoch 17/100\n",
      "\u001b[1m208/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8580 - loss: 0.3441\n",
      "Epoch 17: val_loss did not improve from 0.33477\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8578 - loss: 0.3447 - val_accuracy: 0.8540 - val_loss: 0.3739\n",
      "Epoch 18/100\n",
      "\u001b[1m212/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8629 - loss: 0.3437\n",
      "Epoch 18: val_loss did not improve from 0.33477\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8627 - loss: 0.3441 - val_accuracy: 0.8643 - val_loss: 0.3544\n",
      "Epoch 19/100\n",
      "\u001b[1m196/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8576 - loss: 0.3533\n",
      "Epoch 19: val_loss did not improve from 0.33477\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8579 - loss: 0.3529 - val_accuracy: 0.8647 - val_loss: 0.3377\n",
      "Epoch 20/100\n",
      "\u001b[1m200/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8573 - loss: 0.3502\n",
      "Epoch 20: val_loss did not improve from 0.33477\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8574 - loss: 0.3502 - val_accuracy: 0.8657 - val_loss: 0.3437\n",
      "Epoch 21/100\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8630 - loss: 0.3433\n",
      "Epoch 21: val_loss did not improve from 0.33477\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8628 - loss: 0.3434 - val_accuracy: 0.8580 - val_loss: 0.3740\n",
      "Epoch 22/100\n",
      "\u001b[1m186/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8619 - loss: 0.3457\n",
      "Epoch 22: val_loss did not improve from 0.33477\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8608 - loss: 0.3471 - val_accuracy: 0.8623 - val_loss: 0.3416\n",
      "Epoch 23/100\n",
      "\u001b[1m204/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8607 - loss: 0.3458\n",
      "Epoch 23: val_loss did not improve from 0.33477\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8607 - loss: 0.3457 - val_accuracy: 0.8650 - val_loss: 0.3408\n",
      "Epoch 24/100\n",
      "\u001b[1m182/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8567 - loss: 0.3533\n",
      "Epoch 24: val_loss did not improve from 0.33477\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8571 - loss: 0.3530 - val_accuracy: 0.8650 - val_loss: 0.3436\n",
      "Epoch 25/100\n",
      "\u001b[1m187/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8577 - loss: 0.3466\n",
      "Epoch 25: val_loss did not improve from 0.33477\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8574 - loss: 0.3470 - val_accuracy: 0.8620 - val_loss: 0.3381\n",
      "Epoch 26/100\n",
      "\u001b[1m202/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8649 - loss: 0.3337\n",
      "Epoch 26: val_loss did not improve from 0.33477\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8643 - loss: 0.3348 - val_accuracy: 0.8640 - val_loss: 0.3384\n",
      "Epoch 27/100\n",
      "\u001b[1m214/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8537 - loss: 0.3457\n",
      "Epoch 27: val_loss did not improve from 0.33477\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8538 - loss: 0.3456 - val_accuracy: 0.8630 - val_loss: 0.3389\n",
      "Epoch 28/100\n",
      "\u001b[1m192/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8516 - loss: 0.3475\n",
      "Epoch 28: val_loss did not improve from 0.33477\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8520 - loss: 0.3473 - val_accuracy: 0.8633 - val_loss: 0.3354\n",
      "Epoch 29/100\n",
      "\u001b[1m189/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8534 - loss: 0.3470\n",
      "Epoch 29: val_loss did not improve from 0.33477\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8535 - loss: 0.3470 - val_accuracy: 0.8607 - val_loss: 0.3581\n",
      "Epoch 30/100\n",
      "\u001b[1m214/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8557 - loss: 0.3520\n",
      "Epoch 30: val_loss did not improve from 0.33477\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8558 - loss: 0.3517 - val_accuracy: 0.8640 - val_loss: 0.3383\n",
      "Epoch 31/100\n",
      "\u001b[1m198/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8643 - loss: 0.3325\n",
      "Epoch 31: val_loss did not improve from 0.33477\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8635 - loss: 0.3339 - val_accuracy: 0.8613 - val_loss: 0.3451\n",
      "Epoch 32/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8556 - loss: 0.3421\n",
      "Epoch 32: val_loss did not improve from 0.33477\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8556 - loss: 0.3421 - val_accuracy: 0.8467 - val_loss: 0.3523\n",
      "Epoch 33/100\n",
      "\u001b[1m200/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8563 - loss: 0.3476\n",
      "Epoch 33: val_loss did not improve from 0.33477\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8565 - loss: 0.3473 - val_accuracy: 0.8677 - val_loss: 0.3383\n",
      "Epoch 34/100\n",
      "\u001b[1m194/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8579 - loss: 0.3440\n",
      "Epoch 34: val_loss did not improve from 0.33477\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8580 - loss: 0.3437 - val_accuracy: 0.8657 - val_loss: 0.3355\n",
      "Epoch 35/100\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8577 - loss: 0.3430\n",
      "Epoch 35: val_loss did not improve from 0.33477\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8577 - loss: 0.3430 - val_accuracy: 0.8637 - val_loss: 0.3400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x24b95fd9fd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestmodel.fit(X_train,y_train,validation_data=[X_test,y_test],callbacks=[early_stopping,checkpoint],initial_epoch=11,epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5dd2a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4973716d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the Keras model\n",
    "loaded_model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd8900b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "y_train_pred = loaded_model.predict(X_train)\n",
    "y_train_pred_binary = (y_train_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13296a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8726e89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test,y_pred_binary)\n",
    "accuracy_train = accuracy_score(y_train,y_train_pred_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91e8a614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 0.867\n",
      "train accuracy : 0.8627142857142858\n"
     ]
    }
   ],
   "source": [
    "print('test accuracy :' ,accuracy)\n",
    "print('train accuracy :' ,accuracy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99aff11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8670 - loss: 0.3304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3356480896472931, 0.8612856864929199]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestmodel.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b345ea0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
